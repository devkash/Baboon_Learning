{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "New Basic DNN with Pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfsswF5J7E_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Activation\n",
        "from keras.layers import MaxPooling1D, UpSampling1D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten, Reshape\n",
        "from keras.layers import Input, Dense, Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers.pooling import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rand\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import keras\n",
        "import statistics as st\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2C-ovUl7E_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/Users/Kush/Downloads/refullautoencodercode/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Qf3bxu7FAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import p_f1_recall as metric\n",
        "os.chdir(\"/Users/Kush/Documents/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5hyo6ji7FAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehX2wkR7FAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### HYPERPARAMETERS\n",
        "batch_size, epochs, verbose = 200, 100, 1\n",
        "encoding_dim = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_KkdrDF7FAu",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2b348b4-4581-41bd-f39c-a26139e1432f"
      },
      "source": [
        "##### First proces unlabled data\n",
        "data_u = pd.read_csv('unlabeled_data.csv')\n",
        "print(list(data_u))\n",
        "### Remove unncessary columns\n",
        "data_u = data_u.iloc[:,[3,4,5,7,8,9]]  ## Add 13 if need to keep IDs  ## Drop heading because of low mutual information\n",
        "\n",
        "### Standardize the features\n",
        "def standardize(data,col_nums_to_standardize):\n",
        "    for col in col_nums_to_standardize:\n",
        "        data.iloc[:,col] = (data.iloc[:,col] - np.mean(data.iloc[:,col]))/np.std(data.iloc[:,col])\n",
        "    return data\n",
        "\n",
        "data_u = standardize(data_u,col_nums_to_standardize = range(6))\n",
        "\n",
        "#### Now process the labeled data\n",
        "data_train = pd.read_csv('final_training.csv')\n",
        "data_test = pd.read_csv('final_testing.csv')\n",
        "\n",
        "### Remove unncessary columns\n",
        "data_train = data_train.iloc[:,[3,4,5,7,8,9,10]]  ## Add 13 if need to keep IDs ## Drop heading because of low mutual information\n",
        "data_test = data_test.iloc[:,[3,4,5,7,8,9,10]]\n",
        "\n",
        "### Standardize the features\n",
        "data_train = standardize(data_train,col_nums_to_standardize = range(6))\n",
        "data_test = standardize(data_test,col_nums_to_standardize = range(6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Unnamed: 0', 'COLLAR', 'TIME', 'LAT', 'LON', 'SPEED', 'HEADING', 'X_AXIS', 'Y_AXIS', 'Z_AXIS', 'ID']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sD7Vrh_7FA2",
        "colab_type": "code",
        "colab": {},
        "outputId": "594003ca-8cb1-480c-807a-3bfbc7a23a46"
      },
      "source": [
        "## Split the unlabeled data into training and validation\n",
        "data_u_train, data_u_val = train_test_split(data_u,train_size=0.8,test_size=0.2,shuffle=True)\n",
        "\n",
        "## Split the labeled data into training and validation\n",
        "data_train, data_val = train_test_split(data_train,train_size=0.8,test_size=0.2,shuffle=True)\n",
        "\n",
        "## Seperate features and labels and make labels one-hot\n",
        "def split_fl(df):\n",
        "    return np.array(df.iloc[:,:-1]), np.array(df.iloc[:,-1])\n",
        "\n",
        "train_x, train_y = split_fl(data_train)\n",
        "num_classes = len(set(train_y))\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "val_x, val_y = split_fl(data_val)\n",
        "val_y = to_categorical(val_y)\n",
        "test_x, test_y = split_fl(data_test)\n",
        "test_y = to_categorical(test_y)\n",
        "\n",
        "\n",
        "def build_basicautoencoder(encoding_dim = encoding_dim): \n",
        "    raw_input = Input(shape=(data_u_train.shape[1],))\n",
        "    \n",
        "    encoding_0 = Dense(encoding_dim*6, activation='relu')(raw_input)\n",
        "    encoding_1 = Dense(encoding_dim*4, activation='relu')(encoding_0)\n",
        "    encoding_2 = Dense(encoding_dim*2, activation='relu')(encoding_1)\n",
        "    encoded = Dense(encoding_dim, activation='relu')(encoding_2)\n",
        "    decoding_1 = Dense(encoding_dim*2, activation='relu')(encoded)\n",
        "    decoding_2 = Dense(encoding_dim*4, activation='relu')(decoding_1)\n",
        "    decoding_0 = Dense(encoding_dim*6, activation='relu')(decoding_2)\n",
        "    decoded = Dense(data_u_train.shape[1])(decoding_0)\n",
        "    autoencoder = Model(raw_input, decoded)\n",
        "    encoder = Model(raw_input, encoded)\n",
        "    return autoencoder, encoder\n",
        "    \n",
        "autoencoder, encoder = build_basicautoencoder()\n",
        "init_weights = encoder.get_weights()\n",
        "\n",
        "def autoencoder_train(autoencoder):\n",
        "    autoencoder.compile(optimizer='adam', loss='mse', metrics = ['mse'])\n",
        "    autoencoder.fit(data_u_train, data_u_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                validation_data=(data_u_val, data_u_val),\n",
        "                callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=True)])\n",
        "    loss = autoencoder.evaluate(data_u_val, data_u_val, batch_size=batch_size, verbose=verbose)\n",
        "    return loss\n",
        "\n",
        "autoencoder_loss, autoencoder_loss = autoencoder_train(autoencoder)\n",
        "\n",
        "trained_weights = encoder.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 719888 samples, validate on 179972 samples\n",
            "Epoch 1/100\n",
            "719888/719888 [==============================] - 55s 77us/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
            "Epoch 2/100\n",
            "719888/719888 [==============================] - 53s 73us/step - loss: 7.5851e-04 - mean_squared_error: 7.5851e-04 - val_loss: 2.8211e-04 - val_mean_squared_error: 2.8211e-04\n",
            "Epoch 3/100\n",
            "719888/719888 [==============================] - 71s 99us/step - loss: 5.6943e-04 - mean_squared_error: 5.6943e-04 - val_loss: 6.1829e-04 - val_mean_squared_error: 6.1829e-04\n",
            "Epoch 4/100\n",
            "719888/719888 [==============================] - 104s 144us/step - loss: 5.3232e-04 - mean_squared_error: 5.3232e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 5/100\n",
            "719888/719888 [==============================] - 82s 114us/step - loss: 5.2494e-04 - mean_squared_error: 5.2494e-04 - val_loss: 5.5593e-04 - val_mean_squared_error: 5.5593e-04\n",
            "179972/179972 [==============================] - 10s 55us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cP2oRSik7FA5",
        "colab_type": "code",
        "colab": {},
        "outputId": "d40a47f7-061a-4d78-a8eb-6f4773ae4165"
      },
      "source": [
        "encoder.set_weights(trained_weights)\n",
        "new_layer = Dense(num_classes, activation='softmax')(encoder.output)\n",
        "pre_trained = Model(encoder.input,new_layer)\n",
        "pre_trained.summary()\n",
        "\n",
        "def train_model(model):\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',metric.recall,metric.precision,metric.f1])\n",
        "    model.fit(train_x,train_y,epochs=epochs,batch_size=batch_size,verbose=verbose,validation_data=(val_x,val_y),\n",
        "             callbacks=[EarlyStopping(monitor='val_f1', min_delta=0, patience=3, verbose=0, mode='max', baseline=None, restore_best_weights=True)])\n",
        "    loss,accuracy,recall_score,precision_score,f_score = model.evaluate(val_x, val_y, batch_size=batch_size, verbose=verbose)\n",
        "    return loss,accuracy,recall_score,precision_score,f_score\n",
        "\n",
        "m1_loss,m1_accuracy,m1_recall_score,m1_precision_score,m1_f_score = train_model(pre_trained)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 384)               2688      \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 256)               98560     \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 142,660\n",
            "Trainable params: 142,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 55092 samples, validate on 13773 samples\n",
            "Epoch 1/100\n",
            "55092/55092 [==============================] - 13s 239us/step - loss: 0.7690 - acc: 0.6678 - recall: 0.5511 - precision: 0.7394 - f1: 0.6284 - val_loss: 0.7169 - val_acc: 0.6906 - val_recall: 0.5941 - val_precision: 0.7466 - val_f1: 0.6614\n",
            "Epoch 2/100\n",
            "55092/55092 [==============================] - 6s 113us/step - loss: 0.6950 - acc: 0.6997 - recall: 0.6161 - precision: 0.7606 - f1: 0.6805 - val_loss: 0.6773 - val_acc: 0.7133 - val_recall: 0.6235 - val_precision: 0.7751 - val_f1: 0.6909\n",
            "Epoch 3/100\n",
            "55092/55092 [==============================] - 5s 87us/step - loss: 0.6643 - acc: 0.7158 - recall: 0.6400 - precision: 0.7698 - f1: 0.6987 - val_loss: 0.6677 - val_acc: 0.7179 - val_recall: 0.6588 - val_precision: 0.7607 - val_f1: 0.7060\n",
            "Epoch 4/100\n",
            "55092/55092 [==============================] - 5s 90us/step - loss: 0.6406 - acc: 0.7271 - recall: 0.6599 - precision: 0.7746 - f1: 0.7125 - val_loss: 0.6488 - val_acc: 0.7202 - val_recall: 0.6638 - val_precision: 0.7665 - val_f1: 0.7113\n",
            "Epoch 5/100\n",
            "55092/55092 [==============================] - 5s 90us/step - loss: 0.6270 - acc: 0.7312 - recall: 0.6687 - precision: 0.7776 - f1: 0.7189 - val_loss: 0.6338 - val_acc: 0.7295 - val_recall: 0.6728 - val_precision: 0.7711 - val_f1: 0.7185\n",
            "Epoch 6/100\n",
            "55092/55092 [==============================] - 6s 102us/step - loss: 0.6139 - acc: 0.7369 - recall: 0.6800 - precision: 0.7797 - f1: 0.7262 - val_loss: 0.6337 - val_acc: 0.7255 - val_recall: 0.6738 - val_precision: 0.7661 - val_f1: 0.7169\n",
            "Epoch 7/100\n",
            "55092/55092 [==============================] - 3s 45us/step - loss: 0.6065 - acc: 0.7395 - recall: 0.6835 - precision: 0.7829 - f1: 0.7297 - val_loss: 0.6466 - val_acc: 0.7245 - val_recall: 0.6790 - val_precision: 0.7625 - val_f1: 0.7182\n",
            "Epoch 8/100\n",
            "55092/55092 [==============================] - 2s 45us/step - loss: 0.5959 - acc: 0.7459 - recall: 0.6919 - precision: 0.7861 - f1: 0.7359 - val_loss: 0.6280 - val_acc: 0.7255 - val_recall: 0.6763 - val_precision: 0.7634 - val_f1: 0.7170\n",
            "13773/13773 [==============================] - 0s 20us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UJQKdgWd7FA8",
        "colab_type": "code",
        "colab": {},
        "outputId": "6eaa0a79-627d-4cda-d582-02671956c3d0"
      },
      "source": [
        "### This shows how the model does using the same exact architecture without any pretraining\n",
        "encoder.set_weights(init_weights)\n",
        "new_layer = Dense(num_classes, activation='softmax')(encoder.output)\n",
        "no_pre_train = Model(encoder.input,new_layer)\n",
        "no_pre_train.summary()\n",
        "\n",
        "m2_loss,m2_accuracy,m2_recall_score,m2_precision_score,m2_f_score = train_model(no_pre_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 384)               2688      \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 256)               98560     \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 142,660\n",
            "Trainable params: 142,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 55092 samples, validate on 13773 samples\n",
            "Epoch 1/100\n",
            "55092/55092 [==============================] - 6s 105us/step - loss: 0.7820 - acc: 0.6590 - recall: 0.5259 - precision: 0.7347 - f1: 0.6096 - val_loss: 0.7229 - val_acc: 0.6842 - val_recall: 0.5712 - val_precision: 0.7648 - val_f1: 0.6537\n",
            "Epoch 2/100\n",
            "55092/55092 [==============================] - 2s 41us/step - loss: 0.7098 - acc: 0.6919 - recall: 0.5925 - precision: 0.7592 - f1: 0.6652 - val_loss: 0.6853 - val_acc: 0.7099 - val_recall: 0.6279 - val_precision: 0.7639 - val_f1: 0.6891\n",
            "Epoch 3/100\n",
            "55092/55092 [==============================] - 3s 51us/step - loss: 0.6821 - acc: 0.7052 - recall: 0.6230 - precision: 0.7654 - f1: 0.6866 - val_loss: 0.6755 - val_acc: 0.7133 - val_recall: 0.6464 - val_precision: 0.7610 - val_f1: 0.6990\n",
            "Epoch 4/100\n",
            "55092/55092 [==============================] - 4s 82us/step - loss: 0.6591 - acc: 0.7179 - recall: 0.6448 - precision: 0.7699 - f1: 0.7016 - val_loss: 0.6702 - val_acc: 0.7176 - val_recall: 0.6512 - val_precision: 0.7604 - val_f1: 0.7015\n",
            "Epoch 5/100\n",
            "55092/55092 [==============================] - 7s 127us/step - loss: 0.6430 - acc: 0.7249 - recall: 0.6581 - precision: 0.7724 - f1: 0.7105 - val_loss: 0.6376 - val_acc: 0.7301 - val_recall: 0.6683 - val_precision: 0.7733 - val_f1: 0.7169\n",
            "Epoch 6/100\n",
            "55092/55092 [==============================] - 4s 77us/step - loss: 0.6282 - acc: 0.7317 - recall: 0.6689 - precision: 0.7773 - f1: 0.7188 - val_loss: 0.6311 - val_acc: 0.7263 - val_recall: 0.6704 - val_precision: 0.7700 - val_f1: 0.7166\n",
            "Epoch 7/100\n",
            "55092/55092 [==============================] - 4s 76us/step - loss: 0.6153 - acc: 0.7366 - recall: 0.6790 - precision: 0.7805 - f1: 0.7260 - val_loss: 0.6281 - val_acc: 0.7340 - val_recall: 0.6799 - val_precision: 0.7745 - val_f1: 0.7240\n",
            "Epoch 8/100\n",
            "55092/55092 [==============================] - 4s 75us/step - loss: 0.6031 - acc: 0.7424 - recall: 0.6859 - precision: 0.7834 - f1: 0.7312 - val_loss: 0.6065 - val_acc: 0.7477 - val_recall: 0.6875 - val_precision: 0.7910 - val_f1: 0.7355\n",
            "Epoch 9/100\n",
            "55092/55092 [==============================] - 4s 77us/step - loss: 0.5944 - acc: 0.7470 - recall: 0.6939 - precision: 0.7874 - f1: 0.7376 - val_loss: 0.6167 - val_acc: 0.7363 - val_recall: 0.6790 - val_precision: 0.7776 - val_f1: 0.7249\n",
            "Epoch 10/100\n",
            "55092/55092 [==============================] - 4s 80us/step - loss: 0.5874 - acc: 0.7489 - recall: 0.6974 - precision: 0.7888 - f1: 0.7402 - val_loss: 0.5911 - val_acc: 0.7476 - val_recall: 0.6958 - val_precision: 0.7888 - val_f1: 0.7393\n",
            "Epoch 11/100\n",
            "55092/55092 [==============================] - 5s 85us/step - loss: 0.5798 - acc: 0.7538 - recall: 0.7049 - precision: 0.7911 - f1: 0.7454 - val_loss: 0.5866 - val_acc: 0.7500 - val_recall: 0.7050 - val_precision: 0.7863 - val_f1: 0.7434\n",
            "Epoch 12/100\n",
            "55092/55092 [==============================] - 4s 74us/step - loss: 0.5710 - acc: 0.7578 - recall: 0.7082 - precision: 0.7945 - f1: 0.7487 - val_loss: 0.5886 - val_acc: 0.7509 - val_recall: 0.7105 - val_precision: 0.7819 - val_f1: 0.7444\n",
            "Epoch 13/100\n",
            "55092/55092 [==============================] - 6s 105us/step - loss: 0.5626 - acc: 0.7602 - recall: 0.7145 - precision: 0.7972 - f1: 0.7535 - val_loss: 0.5741 - val_acc: 0.7547 - val_recall: 0.7062 - val_precision: 0.7886 - val_f1: 0.7450\n",
            "Epoch 14/100\n",
            "55092/55092 [==============================] - 2s 42us/step - loss: 0.5582 - acc: 0.7625 - recall: 0.7160 - precision: 0.7996 - f1: 0.7553 - val_loss: 0.5680 - val_acc: 0.7597 - val_recall: 0.7051 - val_precision: 0.8036 - val_f1: 0.7510\n",
            "Epoch 15/100\n",
            "55092/55092 [==============================] - 2s 42us/step - loss: 0.5505 - acc: 0.7667 - recall: 0.7204 - precision: 0.8012 - f1: 0.7586 - val_loss: 0.5636 - val_acc: 0.7611 - val_recall: 0.7131 - val_precision: 0.7976 - val_f1: 0.7528\n",
            "Epoch 16/100\n",
            "55092/55092 [==============================] - 2s 41us/step - loss: 0.5445 - acc: 0.7709 - recall: 0.7246 - precision: 0.8066 - f1: 0.7633 - val_loss: 0.5542 - val_acc: 0.7654 - val_recall: 0.7236 - val_precision: 0.7963 - val_f1: 0.7582\n",
            "Epoch 17/100\n",
            "55092/55092 [==============================] - 2s 41us/step - loss: 0.5407 - acc: 0.7732 - recall: 0.7290 - precision: 0.8073 - f1: 0.7661 - val_loss: 0.5659 - val_acc: 0.7584 - val_recall: 0.7157 - val_precision: 0.7921 - val_f1: 0.7519\n",
            "Epoch 18/100\n",
            "55092/55092 [==============================] - 2s 41us/step - loss: 0.5343 - acc: 0.7750 - recall: 0.7318 - precision: 0.8099 - f1: 0.7687 - val_loss: 0.5807 - val_acc: 0.7536 - val_recall: 0.7062 - val_precision: 0.7912 - val_f1: 0.7462\n",
            "Epoch 19/100\n",
            "55092/55092 [==============================] - 3s 50us/step - loss: 0.5278 - acc: 0.7756 - recall: 0.7346 - precision: 0.8099 - f1: 0.7703 - val_loss: 0.5488 - val_acc: 0.7674 - val_recall: 0.7237 - val_precision: 0.8015 - val_f1: 0.7605\n",
            "Epoch 20/100\n",
            "55092/55092 [==============================] - 3s 52us/step - loss: 0.5226 - acc: 0.7796 - recall: 0.7379 - precision: 0.8125 - f1: 0.7733 - val_loss: 0.5390 - val_acc: 0.7720 - val_recall: 0.7291 - val_precision: 0.8041 - val_f1: 0.7647\n",
            "Epoch 21/100\n",
            "55092/55092 [==============================] - 3s 46us/step - loss: 0.5183 - acc: 0.7803 - recall: 0.7400 - precision: 0.8134 - f1: 0.7749 - val_loss: 0.5307 - val_acc: 0.7764 - val_recall: 0.7361 - val_precision: 0.8099 - val_f1: 0.7711\n",
            "Epoch 22/100\n",
            "55092/55092 [==============================] - 2s 45us/step - loss: 0.5163 - acc: 0.7818 - recall: 0.7423 - precision: 0.8140 - f1: 0.7764 - val_loss: 0.5321 - val_acc: 0.7728 - val_recall: 0.7261 - val_precision: 0.8110 - val_f1: 0.7662\n",
            "Epoch 23/100\n",
            "55092/55092 [==============================] - 3s 51us/step - loss: 0.5106 - acc: 0.7840 - recall: 0.7453 - precision: 0.8165 - f1: 0.7792 - val_loss: 0.5436 - val_acc: 0.7700 - val_recall: 0.7341 - val_precision: 0.8010 - val_f1: 0.7660\n",
            "Epoch 24/100\n",
            "55092/55092 [==============================] - 5s 85us/step - loss: 0.5045 - acc: 0.7862 - recall: 0.7493 - precision: 0.8182 - f1: 0.7821 - val_loss: 0.5358 - val_acc: 0.7741 - val_recall: 0.7346 - val_precision: 0.8068 - val_f1: 0.7689\n",
            "13773/13773 [==============================] - 1s 85us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhPMFIzz7FBA",
        "colab_type": "code",
        "colab": {},
        "outputId": "c6d0c4a1-9cc5-4ac3-9f3e-83159131146c"
      },
      "source": [
        "print(\"autoencoder_loss:\",autoencoder_loss)\n",
        "print(\"pretrained_f1_score:\",m1_f_score)\n",
        "print(\"no_pretrain_f1_score:\",m2_f_score)\n",
        "\n",
        "results.append([autoencoder_loss, m1_f_score, m2_f_score])\n",
        "\n",
        "import os\n",
        "os.system('say \"Done\"')\n",
        "print(len(results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autoencoder_loss: 0.0002821079630246951\n",
            "pretrained_f1_score: 0.7184690528901618\n",
            "no_pretrain_f1_score: 0.7711352526141885\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZWmYPU17FBD",
        "colab_type": "code",
        "colab": {},
        "outputId": "5ef6e595-85bf-42f5-998c-5f3f44cf66ec"
      },
      "source": [
        "temp = np.array(results)\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.41914223e-04, 7.65763990e-01, 7.78080944e-01],\n",
              "       [1.99469743e-04, 7.90588016e-01, 7.73855058e-01],\n",
              "       [2.63841219e-04, 7.93403882e-01, 7.67219435e-01],\n",
              "       [1.73083996e-04, 7.73571999e-01, 7.71384665e-01],\n",
              "       [2.82107963e-04, 7.18469053e-01, 7.71135253e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKPkaMdY7FBH",
        "colab_type": "code",
        "colab": {},
        "outputId": "0401421c-8110-4828-80ba-79f3c84aa1db"
      },
      "source": [
        "np.mean(temp, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.92083429e-04, 7.68359388e-01, 7.72335071e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLRUMi-27FBK",
        "colab_type": "code",
        "colab": {},
        "outputId": "ee034cb1-366a-4713-a3a9-c3553d79854d"
      },
      "source": [
        "np.std(temp, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00013119, 0.02699738, 0.00357318])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_v-xvS7FBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}