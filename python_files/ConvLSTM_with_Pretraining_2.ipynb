{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "testenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "ConvLSTM with Pretraining-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE3RPmwt6Z_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Activation\n",
        "from keras.layers import MaxPooling1D, UpSampling1D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten, Reshape\n",
        "from keras.layers import Input, Dense, Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers.pooling import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rand\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import keras\n",
        "import statistics as st\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPmcKcu6Z_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.chdir(\"/Users/devkash/Desktop/Baboons/Final_Data/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GQ5Tpmf6Z_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import p_f1_recall as metric\n",
        "\n",
        "results = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeMZbTel6Z_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### HYPERPARAMETERS ###\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 200\n",
        "verbose = 1\n",
        "\n",
        "\n",
        "group_size = 60\n",
        "n_sub_group_timesteps = 4\n",
        "num_filters = 128\n",
        "LSTM_nodes = 200\n",
        "encoding_dim = 32\n",
        "BiD = False\n",
        "kernel_size = 2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30kYCKom6Z_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### First proces unlabled data\n",
        "\n",
        "data_u = pd.read_csv('fullest_unlabeled_data.csv')\n",
        "\n",
        "### Remove unncessary columns\n",
        "data_u = data_u.iloc[:,[3,4,5,7,8,9,10]]\n",
        "\n",
        "### Standardize the features\n",
        "def standardize(data,col_nums_to_standardize):\n",
        "    for col in col_nums_to_standardize:\n",
        "        data.iloc[:,col] = (data.iloc[:,col] - np.mean(data.iloc[:,col]))/np.std(data.iloc[:,col])\n",
        "    return data\n",
        "\n",
        "data_u = standardize(data_u,col_nums_to_standardize = range(6))\n",
        "\n",
        "\n",
        "#### Now process the labeled data\n",
        "data_train = pd.read_csv('final_training.csv')\n",
        "data_test = pd.read_csv('final_testing.csv')\n",
        "\n",
        "### Remove unncessary columns\n",
        "data_train = data_train.iloc[:,[3,4,5,7,8,9,10,12]]  ## Add 13 if need to keep IDs ## Drop heading because of low mutual information\n",
        "data_test = data_test.iloc[:,[3,4,5,7,8,9,10,12]]\n",
        "\n",
        "### Standardize the features\n",
        "data_train = standardize(data_train,col_nums_to_standardize = range(6))\n",
        "data_test = standardize(data_test,col_nums_to_standardize = range(6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b18c4jWf6Z_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Break features into groups of size n\n",
        "\n",
        "def break_into_samples(data,group_size):\n",
        "    l = []\n",
        "    sep_ts = set(data.loc[:,'ID'])\n",
        "    for ts in sep_ts:\n",
        "        sub_data  = np.array(data.loc[data.loc[:,'ID']== ts,:])\n",
        "        a = int(sub_data.shape[0]/group_size)\n",
        "        if a != 0:\n",
        "            sub_data = sub_data[:(a*group_size),:]\n",
        "            sub_data = [np.split(sub_data,a)]\n",
        "            l = l + sub_data\n",
        "    data = np.vstack(l)\n",
        "    data = data[:,:,:-1]\n",
        "    return data\n",
        "\n",
        "chunked_data_train = break_into_samples(data_train,group_size)\n",
        "chunked_data_test = break_into_samples(data_test,group_size)\n",
        "chunked_u_data = break_into_samples(data_u,group_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sjrS7yk6Z_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_val(data,labeled = True,thresh = 0.8):\n",
        "    np.random.shuffle(data)\n",
        "    thresh1 = int(data.shape[0]*thresh)\n",
        "    training = data[:thresh1,:,:]\n",
        "    val = data[thresh1:,:,:]\n",
        "    return training, val\n",
        "\n",
        "\n",
        "global_num_classes = -1\n",
        "\n",
        "def split_feat_lab(data,many_to_one = True, prop = 0.65):\n",
        "    features = data[:,:,:data.shape[2]-1]\n",
        "    labels = data[:,:,data.shape[2]-1]\n",
        "    if many_to_one == True:\n",
        "        y_temp = np.zeros(labels.shape[0])\n",
        "        y_temp.fill(np.nan)\n",
        "        for i in range(labels.shape[0]):\n",
        "            row = labels[i,:]\n",
        "            trans_class = (Counter(row)).most_common(1)[0]\n",
        "            if trans_class[1] < group_size*prop : \n",
        "                y_temp[i] = row[1]\n",
        "            else:\n",
        "                 y_temp[i] = st.mode(row)\n",
        "        labels = y_temp\n",
        "        labels = to_categorical(labels,num_classes)\n",
        "        global global_num_classes\n",
        "    if global_num_classes < 0:\n",
        "        global_num_classes = len(set(labels.flatten('C')))\n",
        "    num_classes = global_num_classes\n",
        "    return features,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQlZ8MRy6Z_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunked_data_train1, chunked_data_val = split_train_val(chunked_data_train)\n",
        "training1, val1 = split_train_val(chunked_u_data)\n",
        "\n",
        "train_x1,train_y1 = split_feat_lab(chunked_data_train1,many_to_one = False)\n",
        "val_x1,val_y1 = split_feat_lab(chunked_data_val,many_to_one = False)\n",
        "test_x1,test_y1 = split_feat_lab(chunked_data_test,many_to_one = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1fZqZoI6Z_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_timesteps, n_features = training1.shape[1], training1.shape[2]\n",
        "n_sub_groups = int(n_timesteps/n_sub_group_timesteps)\n",
        "\n",
        "\n",
        "def split_samples_into_sub_samples(features,labels,many_to_one=True,prop=0.65):\n",
        "    features = features.reshape((features.shape[0],n_sub_groups,n_sub_group_timesteps,n_features))\n",
        "    labels = labels\n",
        "    if many_to_one == False:\n",
        "        y_temp = np.zeros((labels.shape[0],n_sub_groups,1))\n",
        "        y_temp.fill(np.nan)\n",
        "        labels = labels.reshape(labels.shape[0],n_sub_groups,n_sub_group_timesteps)\n",
        "        for i in range(labels.shape[0]):\n",
        "            chunk = labels[i,:,:]\n",
        "            for j in range(chunk.shape[0]):\n",
        "                row = chunk[j,:]\n",
        "                trans_class = (Counter(row)).most_common(1)[0]\n",
        "                if trans_class[1] < group_size*0.51:\n",
        "                    y_temp[i,j,0] = row[1]\n",
        "                else:\n",
        "                    y_temp[i,j,0] = st.mode(row)\n",
        "        labels = y_temp\n",
        "        labels = to_categorical(labels)\n",
        "    return features,labels\n",
        "\n",
        "def split_samples_into_sub_samples_u(features):\n",
        "    features = features.reshape((features.shape[0],n_sub_groups,n_sub_group_timesteps,n_features))\n",
        "    return features\n",
        "\n",
        "\n",
        "train_x, train_y = split_samples_into_sub_samples(train_x1, train_y1,many_to_one=False)\n",
        "val_x, val_y = split_samples_into_sub_samples(val_x1, val_y1,many_to_one=False)\n",
        "test_x, test_y = split_samples_into_sub_samples(test_x1, test_y1,many_to_one=False)\n",
        "training = split_samples_into_sub_samples_u(training1)\n",
        "val = split_samples_into_sub_samples_u(val1)\n",
        "\n",
        "### if you get an error here, try rerunning the cell above and then running this one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFddGa6-6Z_7",
        "colab_type": "code",
        "colab": {},
        "outputId": "f4dc45e7-6c24-4f88-a4fe-af0f21deca73"
      },
      "source": [
        "kernel_size = 2\n",
        "def build_full_autoencoder(many_to_one = True, bi_directional = BiD):\n",
        "    raw_input = Input(shape=(n_sub_groups,n_sub_group_timesteps,n_features))\n",
        "    x = TimeDistributed(Conv1D(filters=num_filters, kernel_size=kernel_size, activation=\"relu\",padding='same'),input_shape=(n_sub_groups,n_sub_group_timesteps,n_features))(raw_input)\n",
        "    x = TimeDistributed(Conv1D(filters=num_filters, kernel_size=kernel_size, activation = \"relu\",padding='same'))(x)\n",
        "    x = TimeDistributed(Dropout(0.5))(x)\n",
        "    x = TimeDistributed(MaxPooling1D(pool_size=2))(x)\n",
        "    temp_model = Model(raw_input,x)\n",
        "    shape2 = temp_model.layers[-1].output_shape[1:]\n",
        "    x = TimeDistributed(Flatten())(x)\n",
        "    temp_model = Model(raw_input,x)\n",
        "    shape1=temp_model.layers[-1].output_shape[1:]\n",
        "    if many_to_one == False:\n",
        "        if bi_directional == True:\n",
        "            x=Bidirectional(LSTM(LSTM_nodes,return_sequences=True))(x)\n",
        "        else:\n",
        "            x=LSTM(LSTM_nodes,return_sequences=True)(x)\n",
        "        x=Dropout(0.5)(x)\n",
        "        x=TimeDistributed(Dense(encoding_dim*2, activation='relu'))(x)\n",
        "        encoded=TimeDistributed(Dense(encoding_dim))(x)\n",
        "        encoder = Model(raw_input,encoded)\n",
        "        x=TimeDistributed(Dense(encoding_dim*2, activation='relu'))(encoded)\n",
        "        x=Dropout(0.5)(x)\n",
        "    else:\n",
        "        if bi_directional == True:\n",
        "            x=Bidirectional(LSTM(LSTM_nodes,return_sequences=True))(x)\n",
        "        else:\n",
        "            x=LSTM(LSTM_nodes,return_sequences=True)(x)\n",
        "        x=Dropout(0.5)(x)\n",
        "        x=TimeDistributed(Dense(encoding_dim*2, activation='relu'))(x)\n",
        "        encoded=TimeDistributed(Dense(encoding_dim))(x)\n",
        "        encoder = Model(raw_input,encoded)\n",
        "        x=TimeDistributed(Dense(encoding_dim*2, activation='relu'))(encoded)\n",
        "        x=Dropout(0.5)(x)\n",
        "        x=RepeatVector(n_sub_groups)\n",
        "    if bi_directional == True:\n",
        "        x=Bidirectional(LSTM(LSTM_nodes,return_sequences=True))(x)\n",
        "    else:\n",
        "        x=LSTM(LSTM_nodes,return_sequences=True)(x)\n",
        "    x=TimeDistributed(Dense(shape1[1]))(x)\n",
        "    x=Reshape(shape2)(x)\n",
        "    x=TimeDistributed(UpSampling1D(2))(x)\n",
        "    x=TimeDistributed(Conv1D(filters=num_filters, kernel_size=kernel_size, activation = \"relu\",padding='same'))(x)\n",
        "    x=TimeDistributed(Conv1D(filters=n_features, kernel_size=kernel_size, activation = \"relu\",padding='same'))(x)\n",
        "    autoencoder = Model(raw_input,x)\n",
        "    return autoencoder,encoder\n",
        "\n",
        "\n",
        "autoencoder,encoder = build_full_autoencoder(many_to_one = False, bi_directional = True)\n",
        "autoencoder.summary()\n",
        "encoder.summary()\n",
        "\n",
        "init_weights = encoder.get_weights()\n",
        "\n",
        "def full_auto_train(autoencoder):\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    autoencoder.fit(training, training,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                validation_data=(val, val),\n",
        "                callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=True)])\n",
        "    loss = autoencoder.evaluate(val, val, batch_size=batch_size, verbose=verbose)\n",
        "    return loss\n",
        "\n",
        "autoencoder_loss = full_auto_train(autoencoder)\n",
        "\n",
        "trained_weights = encoder.get_weights()\n",
        "\n",
        "#autoencoder_2 = build_full_autoencoder(many_to_one=False)\n",
        "#autoencoder_2.summary()\n",
        "#full_auto_train(autoencoder_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        (None, 15, 4, 6)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_415 (TimeDi (None, 15, 4, 128)        1664      \n",
            "_________________________________________________________________\n",
            "time_distributed_416 (TimeDi (None, 15, 4, 128)        32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_417 (TimeDi (None, 15, 4, 128)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_418 (TimeDi (None, 15, 2, 128)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_419 (TimeDi (None, 15, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_61 (Bidirectio (None, 15, 400)           731200    \n",
            "_________________________________________________________________\n",
            "dropout_92 (Dropout)         (None, 15, 400)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_420 (TimeDi (None, 15, 64)            25664     \n",
            "_________________________________________________________________\n",
            "time_distributed_421 (TimeDi (None, 15, 32)            2080      \n",
            "_________________________________________________________________\n",
            "time_distributed_422 (TimeDi (None, 15, 64)            2112      \n",
            "_________________________________________________________________\n",
            "dropout_93 (Dropout)         (None, 15, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_62 (Bidirectio (None, 15, 400)           424000    \n",
            "_________________________________________________________________\n",
            "time_distributed_423 (TimeDi (None, 15, 256)           102656    \n",
            "_________________________________________________________________\n",
            "reshape_31 (Reshape)         (None, 15, 2, 128)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_424 (TimeDi (None, 15, 4, 128)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_425 (TimeDi (None, 15, 4, 128)        32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_426 (TimeDi (None, 15, 4, 6)          1542      \n",
            "=================================================================\n",
            "Total params: 1,356,710\n",
            "Trainable params: 1,356,710\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        (None, 15, 4, 6)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_415 (TimeDi (None, 15, 4, 128)        1664      \n",
            "_________________________________________________________________\n",
            "time_distributed_416 (TimeDi (None, 15, 4, 128)        32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_417 (TimeDi (None, 15, 4, 128)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_418 (TimeDi (None, 15, 2, 128)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_419 (TimeDi (None, 15, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_61 (Bidirectio (None, 15, 400)           731200    \n",
            "_________________________________________________________________\n",
            "dropout_92 (Dropout)         (None, 15, 400)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_420 (TimeDi (None, 15, 64)            25664     \n",
            "_________________________________________________________________\n",
            "time_distributed_421 (TimeDi (None, 15, 32)            2080      \n",
            "=================================================================\n",
            "Total params: 793,504\n",
            "Trainable params: 793,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 92838 samples, validate on 23210 samples\n",
            "Epoch 1/100\n",
            "92838/92838 [==============================] - 349s 4ms/step - loss: 0.4923 - val_loss: 0.4736\n",
            "Epoch 2/100\n",
            "92838/92838 [==============================] - 323s 3ms/step - loss: 0.4614 - val_loss: 0.4647\n",
            "Epoch 3/100\n",
            "89000/92838 [===========================>..] - ETA: 12s - loss: 0.4553"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG6VRe9I6Z_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.set_weights(trained_weights)\n",
        "## If many-to-one is true:\n",
        "#new_layer = Dense(global_num_classes, activation='softmax')(encoder.output)\n",
        "# otherwise, use this one:\n",
        "new_layer = TimeDistributed(Dense(global_num_classes, activation='softmax'))(encoder.output)\n",
        "pre_trained = Model(encoder.input,new_layer)\n",
        "pre_trained.summary()\n",
        "\n",
        "def train_model(model):\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',metric.recall,metric.precision,metric.f1])\n",
        "    model.fit(train_x,train_y,epochs=epochs,batch_size=batch_size,verbose=verbose,validation_data=(val_x,val_y),\n",
        "             callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=True), \n",
        "                       TensorBoard(log_dir='./tb')])\n",
        "    loss,accuracy,recall_score,precision_score,f_score = model.evaluate(test_x, test_y, batch_size=batch_size, verbose=verbose)\n",
        "    return loss,accuracy,recall_score,precision_score,f_score\n",
        "\n",
        "m1_loss,m1_accuracy,m1_recall_score,m1_precision_score,m1_f_score = train_model(pre_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3d1pfgL6aAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoder.set_weights(init_weights)\n",
        "## If many-to-one is true:\n",
        "#new_layer = Dense(global_num_classes, activation='softmax')(encoder.output)\n",
        "# otherwise, use this one:\n",
        "#new_layer = TimeDistributed(Dense(global_num_classes, activation='softmax'))(encoder.output)\n",
        "#no_pre_training = Model(encoder.input,new_layer)\n",
        "#no_pre_training.summary()\n",
        "\n",
        "#m2_loss,m2_accuracy,m2_recall_score,m2_precision_score,m2_f_score = train_model(no_pre_training)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9P2cRHf6aAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.append([m1_f_score,m1_accuracy,m1_recall_score,m1_precision_score])\n",
        "import os\n",
        "os.system('say \"done\"')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H71TE2hy6aAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.mean(results,axis=0))\n",
        "print(np.std(results,axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTwFV-0k6aAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}